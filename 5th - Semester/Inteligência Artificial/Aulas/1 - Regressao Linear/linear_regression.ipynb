{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:49:24.963669Z",
     "start_time": "2024-08-18T22:49:24.961730Z"
    }
   },
   "cell_type": "code",
   "source": "# pip install ucimlrepo - primeiro instala-se a lib do repositório",
   "id": "47199f5aa4bb6ad4",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-18T22:49:26.357443Z",
     "start_time": "2024-08-18T22:49:25.008209Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ucimlrepo import fetch_ucirepo "
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:49:29.826634Z",
     "start_time": "2024-08-18T22:49:26.415256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) "
   ],
   "id": "5b7c8ca973d33939",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:49:29.847042Z",
     "start_time": "2024-08-18T22:49:29.844499Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convertendo os dados para um DataFrame\n",
    "df = pd.concat([wine_quality.data.features, wine_quality.data.targets], axis=1)"
   ],
   "id": "e8cf735f1c6b0e4e",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:59:45.929310Z",
     "start_time": "2024-08-18T22:59:45.924495Z"
    }
   },
   "cell_type": "code",
   "source": "df['quality'].value_counts()",
   "id": "54c0ccda2270d135",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2836\n",
       "5    2138\n",
       "7    1079\n",
       "4     216\n",
       "8     193\n",
       "3      30\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:59:49.849742Z",
     "start_time": "2024-08-18T22:59:49.845476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2. Preparação dos dados\n",
    "X = df.drop('quality', axis=1).values  # Todas as colunas exceto 'quality' são características\n",
    "y = df['quality'].values  # A coluna 'quality' é a variável alvo"
   ],
   "id": "223f5473217982d8",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:03.217018Z",
     "start_time": "2024-08-18T23:00:03.210923Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "id": "7422d867f9686f42",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4 ,  0.7 ,  0.  , ...,  3.51,  0.56,  9.4 ],\n",
       "       [ 7.8 ,  0.88,  0.  , ...,  3.2 ,  0.68,  9.8 ],\n",
       "       [ 7.8 ,  0.76,  0.04, ...,  3.26,  0.65,  9.8 ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  2.99,  0.46,  9.4 ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  3.34,  0.38, 12.8 ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  3.26,  0.32, 11.8 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:59:51.812269Z",
     "start_time": "2024-08-18T22:59:51.808424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ],
   "id": "fe03e4b3cf8306fe",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T22:59:54.884967Z",
     "start_time": "2024-08-18T22:59:54.879221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "1348e85033e01960",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:08.042767Z",
     "start_time": "2024-08-18T23:00:08.037686Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convertendo para tensores PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ],
   "id": "95974d2c6f4ec9d9",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:09.126804Z",
     "start_time": "2024-08-18T23:00:09.121996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3. Construir a rede neural\n",
    "class WineQualityNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WineQualityNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(X_train.shape[1], 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "id": "e525a0192f6358bc",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:10.703086Z",
     "start_time": "2024-08-18T23:00:10.698242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Instanciar o modelo\n",
    "model = WineQualityNN()"
   ],
   "id": "5e1d7b2860defb53",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:11.958694Z",
     "start_time": "2024-08-18T23:00:11.572997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Definir a função de perda e o otimizador\n",
    "criterion = nn.MSELoss()  # Usando MSE porque estamos tratando a qualidade como uma variável contínua\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "id": "b224caf97426d5f0",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:14.845503Z",
     "start_time": "2024-08-18T23:00:12.764084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Treinamento do modelo\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ],
   "id": "81662ee5f08ff57a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 33.1677\n",
      "Epoch [2/50], Loss: 32.4250\n",
      "Epoch [3/50], Loss: 31.7007\n",
      "Epoch [4/50], Loss: 30.9907\n",
      "Epoch [5/50], Loss: 30.2900\n",
      "Epoch [6/50], Loss: 29.5937\n",
      "Epoch [7/50], Loss: 28.8958\n",
      "Epoch [8/50], Loss: 28.1919\n",
      "Epoch [9/50], Loss: 27.4777\n",
      "Epoch [10/50], Loss: 26.7501\n",
      "Epoch [11/50], Loss: 26.0076\n",
      "Epoch [12/50], Loss: 25.2484\n",
      "Epoch [13/50], Loss: 24.4710\n",
      "Epoch [14/50], Loss: 23.6747\n",
      "Epoch [15/50], Loss: 22.8590\n",
      "Epoch [16/50], Loss: 22.0241\n",
      "Epoch [17/50], Loss: 21.1705\n",
      "Epoch [18/50], Loss: 20.2998\n",
      "Epoch [19/50], Loss: 19.4140\n",
      "Epoch [20/50], Loss: 18.5157\n",
      "Epoch [21/50], Loss: 17.6075\n",
      "Epoch [22/50], Loss: 16.6923\n",
      "Epoch [23/50], Loss: 15.7734\n",
      "Epoch [24/50], Loss: 14.8544\n",
      "Epoch [25/50], Loss: 13.9392\n",
      "Epoch [26/50], Loss: 13.0320\n",
      "Epoch [27/50], Loss: 12.1373\n",
      "Epoch [28/50], Loss: 11.2599\n",
      "Epoch [29/50], Loss: 10.4045\n",
      "Epoch [30/50], Loss: 9.5763\n",
      "Epoch [31/50], Loss: 8.7802\n",
      "Epoch [32/50], Loss: 8.0214\n",
      "Epoch [33/50], Loss: 7.3049\n",
      "Epoch [34/50], Loss: 6.6353\n",
      "Epoch [35/50], Loss: 6.0171\n",
      "Epoch [36/50], Loss: 5.4539\n",
      "Epoch [37/50], Loss: 4.9489\n",
      "Epoch [38/50], Loss: 4.5039\n",
      "Epoch [39/50], Loss: 4.1201\n",
      "Epoch [40/50], Loss: 3.7970\n",
      "Epoch [41/50], Loss: 3.5328\n",
      "Epoch [42/50], Loss: 3.3244\n",
      "Epoch [43/50], Loss: 3.1670\n",
      "Epoch [44/50], Loss: 3.0546\n",
      "Epoch [45/50], Loss: 2.9802\n",
      "Epoch [46/50], Loss: 2.9359\n",
      "Epoch [47/50], Loss: 2.9135\n",
      "Epoch [48/50], Loss: 2.9049\n",
      "Epoch [49/50], Loss: 2.9027\n",
      "Epoch [50/50], Loss: 2.9006\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:17.995673Z",
     "start_time": "2024-08-18T23:00:17.991778Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Avaliação do modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    mse_loss = criterion(predictions, y_test_tensor)\n",
    "    mae_loss = torch.mean(torch.abs(predictions - y_test_tensor))\n",
    "    print(f'Mean Squared Error on Test Set: {mse_loss.item():.4f}')\n",
    "    print(f'Mean Absolute Error on Test Set: {mae_loss.item():.4f}')"
   ],
   "id": "890a67aa26444a91",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 3.5642\n",
      "Mean Absolute Error on Test Set: 1.3204\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Implementar técnica de data augmentation SMOTE\n",
    "================================================"
   ],
   "id": "afd07646c1e87ec4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:21.565494Z",
     "start_time": "2024-08-18T23:00:21.428406Z"
    }
   },
   "cell_type": "code",
   "source": "from imblearn.over_sampling import SMOTE",
   "id": "607eb0673c559260",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:22.370034Z",
     "start_time": "2024-08-18T23:00:22.366536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Criar uma máscara para identificar as classes de interesse (qualidade acima de 7 e abaixo de 5)\n",
    "mask = (y > 7) | (y < 5)"
   ],
   "id": "d5eb3658a5764a14",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:23.855486Z",
     "start_time": "2024-08-18T23:00:23.830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aplicar SMOTE para as classes minoritárias (qualidade > 7 e < 5)\n",
    "smote = SMOTE(k_neighbors=3)  # Ajustando n_neighbors para um valor menor\n",
    "X_smote, y_smote = smote.fit_resample(X[mask], y[mask])"
   ],
   "id": "b291ed28f5fa373",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:26.016131Z",
     "start_time": "2024-08-18T23:00:26.011657Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combinar as amostras SMOTE com as instâncias que têm qualidade entre 5 e 7\n",
    "mask_middle = (y >= 5) & (y <= 7)\n",
    "X_final = np.vstack([X_smote, X[mask_middle]])\n",
    "y_final = np.hstack([y_smote, y[mask_middle]])"
   ],
   "id": "36d4b92d41fde141",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:28.178359Z",
     "start_time": "2024-08-18T23:00:28.172683Z"
    }
   },
   "cell_type": "code",
   "source": "X_final",
   "id": "1a3714448af31eba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4 ,  0.59,  0.08, ...,  3.38,  0.5 ,  9.  ],\n",
       "       [ 5.7 ,  1.13,  0.09, ...,  3.5 ,  0.48,  9.8 ],\n",
       "       [ 8.8 ,  0.61,  0.3 , ...,  3.26,  0.51,  9.3 ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  2.99,  0.46,  9.4 ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  3.34,  0.38, 12.8 ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  3.26,  0.32, 11.8 ]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:31.485313Z",
     "start_time": "2024-08-18T23:00:31.480393Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.2, random_state=42)"
   ],
   "id": "69c68e365e8cde19",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:34.024780Z",
     "start_time": "2024-08-18T23:00:34.017467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ],
   "id": "a35660e0df4a29e7",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:35.062354Z",
     "start_time": "2024-08-18T23:00:35.057381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convertendo para tensores PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ],
   "id": "7cecfaa74acd3938",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:37.574317Z",
     "start_time": "2024-08-18T23:00:37.415131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Treinamento do modelo\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ],
   "id": "a1aacf98a032ac06",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 3.7834\n",
      "Epoch [2/50], Loss: 3.7507\n",
      "Epoch [3/50], Loss: 3.7065\n",
      "Epoch [4/50], Loss: 3.6509\n",
      "Epoch [5/50], Loss: 3.5852\n",
      "Epoch [6/50], Loss: 3.5115\n",
      "Epoch [7/50], Loss: 3.4324\n",
      "Epoch [8/50], Loss: 3.3504\n",
      "Epoch [9/50], Loss: 3.2682\n",
      "Epoch [10/50], Loss: 3.1881\n",
      "Epoch [11/50], Loss: 3.1119\n",
      "Epoch [12/50], Loss: 3.0412\n",
      "Epoch [13/50], Loss: 2.9768\n",
      "Epoch [14/50], Loss: 2.9193\n",
      "Epoch [15/50], Loss: 2.8686\n",
      "Epoch [16/50], Loss: 2.8243\n",
      "Epoch [17/50], Loss: 2.7859\n",
      "Epoch [18/50], Loss: 2.7526\n",
      "Epoch [19/50], Loss: 2.7236\n",
      "Epoch [20/50], Loss: 2.6979\n",
      "Epoch [21/50], Loss: 2.6745\n",
      "Epoch [22/50], Loss: 2.6527\n",
      "Epoch [23/50], Loss: 2.6318\n",
      "Epoch [24/50], Loss: 2.6111\n",
      "Epoch [25/50], Loss: 2.5903\n",
      "Epoch [26/50], Loss: 2.5692\n",
      "Epoch [27/50], Loss: 2.5475\n",
      "Epoch [28/50], Loss: 2.5252\n",
      "Epoch [29/50], Loss: 2.5025\n",
      "Epoch [30/50], Loss: 2.4793\n",
      "Epoch [31/50], Loss: 2.4561\n",
      "Epoch [32/50], Loss: 2.4329\n",
      "Epoch [33/50], Loss: 2.4101\n",
      "Epoch [34/50], Loss: 2.3878\n",
      "Epoch [35/50], Loss: 2.3663\n",
      "Epoch [36/50], Loss: 2.3457\n",
      "Epoch [37/50], Loss: 2.3261\n",
      "Epoch [38/50], Loss: 2.3076\n",
      "Epoch [39/50], Loss: 2.2901\n",
      "Epoch [40/50], Loss: 2.2736\n",
      "Epoch [41/50], Loss: 2.2581\n",
      "Epoch [42/50], Loss: 2.2434\n",
      "Epoch [43/50], Loss: 2.2295\n",
      "Epoch [44/50], Loss: 2.2161\n",
      "Epoch [45/50], Loss: 2.2032\n",
      "Epoch [46/50], Loss: 2.1907\n",
      "Epoch [47/50], Loss: 2.1783\n",
      "Epoch [48/50], Loss: 2.1662\n",
      "Epoch [49/50], Loss: 2.1542\n",
      "Epoch [50/50], Loss: 2.1422\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:00:39.683562Z",
     "start_time": "2024-08-18T23:00:39.678569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Avaliação do modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    mse_loss = criterion(predictions, y_test_tensor)\n",
    "    mae_loss = torch.mean(torch.abs(predictions - y_test_tensor))\n",
    "    print(f'Mean Squared Error on Test Set: {mse_loss.item():.4f}')\n",
    "    print(f'Mean Absolute Error on Test Set: {mae_loss.item():.4f}')"
   ],
   "id": "d2e1fc89222b0d12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 2.2366\n",
      "Mean Absolute Error on Test Set: 1.1270\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Inserir Mix-Up\n",
    "==============="
   ],
   "id": "52e043f7fbd7b11d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:05:44.020868Z",
     "start_time": "2024-08-18T23:05:44.017014Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Função MixUp para gerar mais instâncias\n",
    "def mixup(X, y, alpha=0.2, n_samples=2):\n",
    "    X_mix = []\n",
    "    y_mix = []\n",
    "    \n",
    "    for _ in range(n_samples):\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        \n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "        \n",
    "        X_mixed = lam * X + (1 - lam) * X_shuffled\n",
    "        y_mixed = lam * y + (1 - lam) * y_shuffled\n",
    "        \n",
    "        X_mix.append(X_mixed)\n",
    "        y_mix.append(y_mixed)\n",
    "    \n",
    "    return np.vstack(X_mix), np.hstack(y_mix)"
   ],
   "id": "41b79b59557c1be2",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:05:46.574532Z",
     "start_time": "2024-08-18T23:05:46.568169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aplicar MixUp dentro de cada grupo de qualidade\n",
    "X_mix = []\n",
    "y_mix = []\n",
    "\n",
    "for quality in np.unique(y_final):\n",
    "    X_group = X_final[y_final == quality]\n",
    "    y_group = y_final[y_final == quality]\n",
    "    \n",
    "    X_mixed, y_mixed = mixup(X_group, y_group)\n",
    "    \n",
    "    X_mix.append(X_mixed)\n",
    "    y_mix.append(y_mixed)\n",
    "\n",
    "# Combinar as amostras mixadas de volta em um único conjunto de dados\n",
    "X_combined = np.vstack(X_mix)\n",
    "y_combined = np.hstack(y_mix)"
   ],
   "id": "6e542014667c16f7",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:05:48.351184Z",
     "start_time": "2024-08-18T23:05:48.347212Z"
    }
   },
   "cell_type": "code",
   "source": "X_combined",
   "id": "f31de2576324d89e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.3606451 ,  0.4495194 ,  0.47895105, ...,  3.15383408,\n",
       "         0.53884877,  9.35214647],\n",
       "       [ 9.69683263,  0.56804031,  0.47274674, ...,  3.13703189,\n",
       "         0.59668866,  9.06057724],\n",
       "       [ 7.38473261,  0.86763757,  0.1406929 , ...,  3.43100533,\n",
       "         0.51296999, 10.7904761 ],\n",
       "       ...,\n",
       "       [ 8.15961349,  0.25340494,  0.40021483, ...,  3.24425348,\n",
       "         0.47106337, 11.56165392],\n",
       "       [ 6.66617821,  0.34676463,  0.31647096, ...,  3.40470526,\n",
       "         0.58485166, 12.46617821],\n",
       "       [ 7.01509994,  0.30246679,  0.42629684, ...,  3.33178226,\n",
       "         0.3945329 , 12.81499347]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:05:59.693079Z",
     "start_time": "2024-08-18T23:05:59.682642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convertendo para tensores PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ],
   "id": "5df03ec22dfb0034",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:06:01.759559Z",
     "start_time": "2024-08-18T23:06:01.562434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Treinamento do modelo\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ],
   "id": "e0bd37f72a2b9a68",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 1.9539\n",
      "Epoch [2/50], Loss: 1.9432\n",
      "Epoch [3/50], Loss: 1.9326\n",
      "Epoch [4/50], Loss: 1.9220\n",
      "Epoch [5/50], Loss: 1.9115\n",
      "Epoch [6/50], Loss: 1.9011\n",
      "Epoch [7/50], Loss: 1.8909\n",
      "Epoch [8/50], Loss: 1.8808\n",
      "Epoch [9/50], Loss: 1.8710\n",
      "Epoch [10/50], Loss: 1.8613\n",
      "Epoch [11/50], Loss: 1.8519\n",
      "Epoch [12/50], Loss: 1.8427\n",
      "Epoch [13/50], Loss: 1.8337\n",
      "Epoch [14/50], Loss: 1.8249\n",
      "Epoch [15/50], Loss: 1.8163\n",
      "Epoch [16/50], Loss: 1.8078\n",
      "Epoch [17/50], Loss: 1.7994\n",
      "Epoch [18/50], Loss: 1.7911\n",
      "Epoch [19/50], Loss: 1.7829\n",
      "Epoch [20/50], Loss: 1.7749\n",
      "Epoch [21/50], Loss: 1.7668\n",
      "Epoch [22/50], Loss: 1.7589\n",
      "Epoch [23/50], Loss: 1.7511\n",
      "Epoch [24/50], Loss: 1.7433\n",
      "Epoch [25/50], Loss: 1.7356\n",
      "Epoch [26/50], Loss: 1.7280\n",
      "Epoch [27/50], Loss: 1.7205\n",
      "Epoch [28/50], Loss: 1.7130\n",
      "Epoch [29/50], Loss: 1.7057\n",
      "Epoch [30/50], Loss: 1.6984\n",
      "Epoch [31/50], Loss: 1.6912\n",
      "Epoch [32/50], Loss: 1.6841\n",
      "Epoch [33/50], Loss: 1.6771\n",
      "Epoch [34/50], Loss: 1.6702\n",
      "Epoch [35/50], Loss: 1.6633\n",
      "Epoch [36/50], Loss: 1.6565\n",
      "Epoch [37/50], Loss: 1.6498\n",
      "Epoch [38/50], Loss: 1.6431\n",
      "Epoch [39/50], Loss: 1.6365\n",
      "Epoch [40/50], Loss: 1.6299\n",
      "Epoch [41/50], Loss: 1.6234\n",
      "Epoch [42/50], Loss: 1.6169\n",
      "Epoch [43/50], Loss: 1.6105\n",
      "Epoch [44/50], Loss: 1.6041\n",
      "Epoch [45/50], Loss: 1.5977\n",
      "Epoch [46/50], Loss: 1.5914\n",
      "Epoch [47/50], Loss: 1.5852\n",
      "Epoch [48/50], Loss: 1.5789\n",
      "Epoch [49/50], Loss: 1.5727\n",
      "Epoch [50/50], Loss: 1.5666\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:06:04.396042Z",
     "start_time": "2024-08-18T23:06:04.391253Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Avaliação do modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    mse_loss = criterion(predictions, y_test_tensor)\n",
    "    mae_loss = torch.mean(torch.abs(predictions - y_test_tensor))\n",
    "    print(f'Mean Squared Error on Test Set: {mse_loss.item():.4f}')\n",
    "    print(f'Mean Absolute Error on Test Set: {mae_loss.item():.4f}')"
   ],
   "id": "f691d7ca4b91862f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 1.4755\n",
      "Mean Absolute Error on Test Set: 0.9388\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Inserir ruído gaussiano\n",
    "======================="
   ],
   "id": "e248c39cdb9f6807"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:10:04.847598Z",
     "start_time": "2024-08-18T23:10:04.843133Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aplicar ruído gaussiano segmentado pela classe quality\n",
    "def add_gaussian_noise(X, mean=0, stddev=0.1):\n",
    "    noise = np.random.normal(mean, stddev, X.shape)\n",
    "    return X + noise"
   ],
   "id": "9822ee5d9ff955b3",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:10:06.592978Z",
     "start_time": "2024-08-18T23:10:06.584113Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_noisy = []\n",
    "y_noisy = []\n",
    "\n",
    "for quality in np.unique(y_combined):\n",
    "    X_group = X_combined[y_combined == quality]\n",
    "    y_group = y_combined[y_combined == quality]\n",
    "    \n",
    "    X_group_noisy = add_gaussian_noise(X_group)\n",
    "    \n",
    "    X_noisy.append(X_group_noisy)\n",
    "    y_noisy.append(y_group)\n",
    "\n",
    "# Combinar as amostras com ruído de volta em um único conjunto de dados\n",
    "X_final_noisy = np.vstack([X_combined] + X_noisy)\n",
    "y_final_noisy = np.hstack([y_combined] + y_noisy)"
   ],
   "id": "7627011df8b77b20",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:10:14.039680Z",
     "start_time": "2024-08-18T23:10:14.035380Z"
    }
   },
   "cell_type": "code",
   "source": "X_final_noisy",
   "id": "c0b18969d97c7e35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.3606451 ,  0.4495194 ,  0.47895105, ...,  3.15383408,\n",
       "         0.53884877,  9.35214647],\n",
       "       [ 9.69683263,  0.56804031,  0.47274674, ...,  3.13703189,\n",
       "         0.59668866,  9.06057724],\n",
       "       [ 7.38473261,  0.86763757,  0.1406929 , ...,  3.43100533,\n",
       "         0.51296999, 10.7904761 ],\n",
       "       ...,\n",
       "       [ 8.10427668,  0.14396187,  0.59156379, ...,  3.16690746,\n",
       "         0.33553317, 11.72847718],\n",
       "       [ 6.58089145,  0.25502186,  0.27525059, ...,  3.45401118,\n",
       "         0.51736464, 12.48341482],\n",
       "       [ 6.88709876,  0.41315748,  0.41099086, ...,  3.31969781,\n",
       "         0.43249432, 12.84239108]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:10:36.580779Z",
     "start_time": "2024-08-18T23:10:36.568324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dividindo os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final_noisy, y_final_noisy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalizando os dados\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convertendo para tensores PyTorch\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)"
   ],
   "id": "1dcdfb689818d4c",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:11:01.946350Z",
     "start_time": "2024-08-18T23:11:01.603522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4. Treinamento do modelo\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ],
   "id": "803b4f863c27962c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.9309\n",
      "Epoch [2/50], Loss: 2.9132\n",
      "Epoch [3/50], Loss: 2.8846\n",
      "Epoch [4/50], Loss: 2.8472\n",
      "Epoch [5/50], Loss: 2.8033\n",
      "Epoch [6/50], Loss: 2.7546\n",
      "Epoch [7/50], Loss: 2.7027\n",
      "Epoch [8/50], Loss: 2.6490\n",
      "Epoch [9/50], Loss: 2.5944\n",
      "Epoch [10/50], Loss: 2.5399\n",
      "Epoch [11/50], Loss: 2.4861\n",
      "Epoch [12/50], Loss: 2.4335\n",
      "Epoch [13/50], Loss: 2.3823\n",
      "Epoch [14/50], Loss: 2.3330\n",
      "Epoch [15/50], Loss: 2.2856\n",
      "Epoch [16/50], Loss: 2.2402\n",
      "Epoch [17/50], Loss: 2.1971\n",
      "Epoch [18/50], Loss: 2.1561\n",
      "Epoch [19/50], Loss: 2.1174\n",
      "Epoch [20/50], Loss: 2.0811\n",
      "Epoch [21/50], Loss: 2.0473\n",
      "Epoch [22/50], Loss: 2.0159\n",
      "Epoch [23/50], Loss: 1.9868\n",
      "Epoch [24/50], Loss: 1.9600\n",
      "Epoch [25/50], Loss: 1.9352\n",
      "Epoch [26/50], Loss: 1.9123\n",
      "Epoch [27/50], Loss: 1.8910\n",
      "Epoch [28/50], Loss: 1.8712\n",
      "Epoch [29/50], Loss: 1.8528\n",
      "Epoch [30/50], Loss: 1.8355\n",
      "Epoch [31/50], Loss: 1.8193\n",
      "Epoch [32/50], Loss: 1.8040\n",
      "Epoch [33/50], Loss: 1.7895\n",
      "Epoch [34/50], Loss: 1.7758\n",
      "Epoch [35/50], Loss: 1.7628\n",
      "Epoch [36/50], Loss: 1.7504\n",
      "Epoch [37/50], Loss: 1.7385\n",
      "Epoch [38/50], Loss: 1.7271\n",
      "Epoch [39/50], Loss: 1.7161\n",
      "Epoch [40/50], Loss: 1.7054\n",
      "Epoch [41/50], Loss: 1.6950\n",
      "Epoch [42/50], Loss: 1.6849\n",
      "Epoch [43/50], Loss: 1.6749\n",
      "Epoch [44/50], Loss: 1.6652\n",
      "Epoch [45/50], Loss: 1.6556\n",
      "Epoch [46/50], Loss: 1.6461\n",
      "Epoch [47/50], Loss: 1.6368\n",
      "Epoch [48/50], Loss: 1.6276\n",
      "Epoch [49/50], Loss: 1.6185\n",
      "Epoch [50/50], Loss: 1.6095\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-18T23:11:04.560239Z",
     "start_time": "2024-08-18T23:11:04.556857Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 5. Avaliação do modelo\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = model(X_test_tensor)\n",
    "    mse_loss = criterion(predictions, y_test_tensor)\n",
    "    mae_loss = torch.mean(torch.abs(predictions - y_test_tensor))\n",
    "    print(f'Mean Squared Error on Test Set: {mse_loss.item():.4f}')\n",
    "    print(f'Mean Absolute Error on Test Set: {mae_loss.item():.4f}')"
   ],
   "id": "1467fae280c0d140",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error on Test Set: 1.5883\n",
      "Mean Absolute Error on Test Set: 0.9762\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
